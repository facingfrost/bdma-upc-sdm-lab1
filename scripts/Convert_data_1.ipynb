{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (0) Import packages and Export function define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "# def export_to_csv(data, output_file):\n",
    "#     if isinstance(data, dict):\n",
    "#         fieldnames = list(data.keys())\n",
    "#     elif isinstance(data, list) and isinstance(data[0], dict):\n",
    "#         fieldnames = list(data[0].keys())\n",
    "#     else:\n",
    "#         raise ValueError(\"Invalid data format\")\n",
    "\n",
    "#     with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "#         writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "#         writer.writeheader()\n",
    "\n",
    "#         if isinstance(data, dict):\n",
    "#             writer.writerow(data)\n",
    "#         elif isinstance(data, list):\n",
    "#             for row_data in data:\n",
    "#                 writer.writerow(row_data)\n",
    "def export_to_csv(data, output_file):\n",
    "    fieldnames = list(data.keys())\n",
    "\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # zip every key values and write into csv\n",
    "        for row_data in zip(*data.values()):\n",
    "            writer.writerow({field: value for field, value in zip(fieldnames, row_data)})\n",
    "\n",
    "\n",
    "file_path = \"/Users/zzy13/Desktop/Classes_at_UPC/SDM_Semantic_data_management/Lab_1/Codes/Data\"\n",
    "data_name = \"sample.csv\"\n",
    "input_file_path = os.path.join(file_path, data_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper.csv文件已导出到: /Users/zzy13/Desktop/Classes_at_UPC/SDM_Semantic_data_management/Lab_1/Codes/Data/paper.csv\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "#################  Paper       ###################################################\n",
    "####################################################################################\n",
    "def extract_data_from_csv(file_path):\n",
    "    papers = {\n",
    "        \"title\": [],\n",
    "        \"abstract\": [],\n",
    "        \"pages\": [],\n",
    "        \"DOI\": [],\n",
    "        \"link\": []\n",
    "    }\n",
    "\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for idx, row in enumerate(reader):\n",
    "            papers[\"title\"].append(row[\"Title\"])\n",
    "            papers[\"abstract\"].append(row[\"Abstract\"])\n",
    "            papers[\"pages\"].append(f\"{row['Page start']}-{row['Page end']}\")\n",
    "            papers[\"DOI\"].append(row[\"DOI\"])\n",
    "            papers[\"link\"].append(row[\"Link\"])\n",
    "\n",
    "    return papers\n",
    "# def export_to_csv(data, output_file):\n",
    "#     fieldnames = list(data.keys())\n",
    "\n",
    "#     with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "#         writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "#         writer.writeheader()\n",
    "#         for row_data in zip(*data.values()):\n",
    "#             writer.writerow({field: value for field, value in zip(fieldnames, row_data)})\n",
    "\n",
    "# write paper.csv\n",
    "papers_data = extract_data_from_csv(input_file_path)\n",
    "paper_name = 'paper.csv'\n",
    "output_file_path = os.path.join(file_path, paper_name)\n",
    "export_to_csv(papers_data, output_file_path)\n",
    "print(\"paper.csv write to:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "journal.csv数据已导出到: /Users/zzy13/Desktop/Classes_at_UPC/SDM_Semantic_data_management/Lab_1/Codes/Data/journal.csv\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "#################  Journal       ###################################################\n",
    "####################################################################################\n",
    "# Print Journal table\n",
    "def extract_journals_from_csv(file_path):\n",
    "    journals = {\"name\": []}\n",
    "\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            conference_name = row[\"Conference name\"]\n",
    "            if not conference_name:  # if Conference name IS empty，regarding as journal\n",
    "                journals[\"name\"].append(row[\"Source title\"])\n",
    "    journals[\"name\"] = list(set(journals[\"name\"]))\n",
    "    return journals\n",
    "\n",
    "# extract journal information\n",
    "journal_data = extract_journals_from_csv(input_file_path)\n",
    "journal_name = 'journal.csv'\n",
    "# write journal.csv\n",
    "output_file_path = os.path.join(file_path, journal_name)\n",
    "export_to_csv(journal_data, output_file_path)\n",
    "print(\"journal.csv write to:\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proceeding.csv数据已导出到: /Users/zzy13/Desktop/Classes_at_UPC/SDM_Semantic_data_management/Lab_1/Codes/Data/proceeding.csv\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "#################  Proceedings       ###################################################\n",
    "####################################################################################\n",
    "def extract_proceeding_from_csv(file_path):\n",
    "    proceeding = {\"name\": []}\n",
    "\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            conference_name = row[\"Conference name\"]\n",
    "            if conference_name:  # if Conference name NOT empty，regarding as proceeding\n",
    "                proceeding[\"name\"].append(row[\"Source title\"])\n",
    "    \n",
    "    # Deduplicate\n",
    "    proceeding[\"name\"] = list(set(proceeding[\"name\"]))\n",
    "    return proceeding\n",
    "# extract proceeding info\n",
    "proceeding_data = extract_proceeding_from_csv(input_file_path)\n",
    "proceeding_name = 'proceeding.csv'\n",
    "# write proceeding.csv \n",
    "output_file_path = os.path.join(file_path, proceeding_name)\n",
    "export_to_csv(proceeding_data, output_file_path)\n",
    "print(\"proceeding.csv write to:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conference.csv数据已导出到: /Users/zzy13/Desktop/Classes_at_UPC/SDM_Semantic_data_management/Lab_1/Codes/Data/conference.csv\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "#################  Conference       ################################################\n",
    "####################################################################################\n",
    "def extract_conference_from_csv(file_path):\n",
    "    conferences = {\"name\": [], \"year\": [], \"city\": []}\n",
    "\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            conference_name = row[\"Conference name\"].strip()\n",
    "            if conference_name:\n",
    "                conferences[\"name\"].append(conference_name)\n",
    "                year_match = re.search(r'\\d{4}', row[\"Conference date\"])\n",
    "                year = year_match.group(0) if year_match else None\n",
    "                conferences[\"year\"].append(year)\n",
    "                conferences[\"city\"].append(row[\"Conference location\"].strip())\n",
    "    \n",
    "    # deduplicate\n",
    "    unique_conferences = []\n",
    "    seen = set()\n",
    "    for name, year, city in zip(conferences[\"name\"], conferences[\"year\"], conferences[\"city\"]):\n",
    "        if name not in seen:\n",
    "            seen.add(name)\n",
    "            unique_conferences.append({\"name\": name, \"year\": year, \"city\": city})\n",
    "    \n",
    "    return unique_conferences\n",
    "\n",
    "def export_conference_to_csv(data, output_file):\n",
    "    if not data:\n",
    "        return\n",
    "\n",
    "    fieldnames = list(data[0].keys())\n",
    "\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for row_data in data:\n",
    "            writer.writerow(row_data)\n",
    "\n",
    "# extract\n",
    "conference_data = extract_conference_from_csv(input_file_path)\n",
    "conference_name = 'conference.csv'\n",
    "# write csv\n",
    "output_file_path = os.path.join(file_path, conference_name)\n",
    "export_conference_to_csv(conference_data, output_file_path)\n",
    "print(\"conference.csv write to:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (2) Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conference_proceeding.csv 数据已导出到: /Users/zzy13/Desktop/Classes_at_UPC/SDM_Semantic_data_management/Lab_1/Codes/Data/conference_belong_to_proceeding.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "####################################################################################\n",
    "#################  conference_belong_to_proceedings       ################################################\n",
    "####################################################################################\n",
    "\n",
    "def extract_conference_proceeding_from_csv(file_path):\n",
    "    conference_proceeding = {\"start_id\": [], \"end_id\": []}\n",
    "    seen_combinations = set()\n",
    "\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            conference_name = row[\"Conference name\"].strip()\n",
    "            source_title = row[\"Source title\"].strip()\n",
    "            if conference_name and source_title:\n",
    "                combined_key = (conference_name, source_title)\n",
    "                if combined_key not in seen_combinations:\n",
    "                    seen_combinations.add(combined_key)\n",
    "                    conference_proceeding[\"start_id\"].append(conference_name)\n",
    "                    conference_proceeding[\"end_id\"].append(source_title)\n",
    "\n",
    "    return conference_proceeding\n",
    "\n",
    "# extract\n",
    "conference_proceeding_data = extract_conference_proceeding_from_csv(input_file_path)\n",
    "\n",
    "# write csv\n",
    "output_file_name = \"conference_belong_to_proceeding.csv\"\n",
    "output_file_path = os.path.join(file_path, output_file_name)\n",
    "export_to_csv(conference_proceeding_data, output_file_path)\n",
    "\n",
    "print(\"conference_proceeding.csv  write to:\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper_proceeding.csv 数据已导出到: /Users/zzy13/Desktop/Classes_at_UPC/SDM_Semantic_data_management/Lab_1/Codes/Data/paper_belong_to_proceeding.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "####################################################################################\n",
    "#################  paper_belong_to_proceedings       ################################################\n",
    "####################################################################################\n",
    "\n",
    "def extract_paper_proceeding_from_csv(file_path):\n",
    "    paper_proceeding = {\"start_id\": [], \"end_id\": []}\n",
    "    seen_combinations = set()\n",
    "\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            DOI = row[\"DOI\"].strip()\n",
    "            conference_name = row[\"Conference name\"].strip()\n",
    "            source_title = row[\"Source title\"].strip()\n",
    "            if conference_name and source_title:\n",
    "                combined_key = (DOI, source_title)\n",
    "                if combined_key not in seen_combinations:\n",
    "                    seen_combinations.add(combined_key)\n",
    "                    paper_proceeding[\"start_id\"].append(DOI)\n",
    "                    paper_proceeding[\"end_id\"].append(source_title)\n",
    "\n",
    "    return paper_proceeding\n",
    "\n",
    "#  extract\n",
    "paper_proceeding_data = extract_paper_proceeding_from_csv(input_file_path)\n",
    "\n",
    "# write csv\n",
    "output_file_name = \"paper_belong_to_proceeding.csv\"\n",
    "output_file_path = os.path.join(file_path, output_file_name)\n",
    "export_to_csv(paper_proceeding_data, output_file_path)\n",
    "\n",
    "print(\"paper_proceeding.csv  write to:\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper_journal.csv 数据已导出到: /Users/zzy13/Desktop/Classes_at_UPC/SDM_Semantic_data_management/Lab_1/Codes/Data/paper_belong_to_journal.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "####################################################################################\n",
    "#################  paper_belong_to_journal       ################################################\n",
    "####################################################################################\n",
    "def extract_paper_journal_from_csv(file_path):\n",
    "    paper_journal = {\"start_id\": [], \"end_id\": []}\n",
    "    seen_combinations = set()\n",
    "\n",
    "    with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            DOI = row[\"DOI\"].strip()\n",
    "            conference_name = row[\"Conference name\"].strip()\n",
    "            source_title = row[\"Source title\"].strip()\n",
    "            if not conference_name:\n",
    "                combined_key = (DOI, source_title)\n",
    "                if combined_key not in seen_combinations:\n",
    "                    seen_combinations.add(combined_key)\n",
    "                    paper_journal[\"start_id\"].append(DOI)\n",
    "                    paper_journal[\"end_id\"].append(source_title)\n",
    "\n",
    "    return paper_journal\n",
    "\n",
    "# extract info\n",
    "paper_journal_data = extract_paper_journal_from_csv(input_file_path)\n",
    "\n",
    "# write CSV\n",
    "output_file_name = \"paper_belong_to_journal.csv\"\n",
    "output_file_path = os.path.join(file_path, output_file_name)\n",
    "export_to_csv(paper_journal_data, output_file_path)\n",
    "\n",
    "print(\"paper_journal.csv write to:\", output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper_cite_paper.csv 数据已导出到: /Users/zzy13/Desktop/Classes_at_UPC/SDM_Semantic_data_management/Lab_1/Codes/Data/paper_cite_paper.csv\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "#################  paper_cite_paper       ###########################################\n",
    "####################################################################################\n",
    "### Assumption is paper is cited by [0-50] papers\n",
    "\n",
    "def generate_paper_cite_paper(input_file_path):\n",
    "    paper_cite_paper = {\"start_id\": [], \"end_id\": []}\n",
    "    \n",
    "    # open sample.csv\n",
    "    with open(input_file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        dois = [row[\"DOI\"].strip() for row in reader if row[\"DOI\"].strip()]\n",
    "\n",
    "    # for every DOI\n",
    "    for doi in dois:\n",
    "        # randomly select DOI which are different from the current DOI\n",
    "        end_dois = random.sample([d for d in dois if d != doi], min(random.randint(0, 50), len(dois) - 1))\n",
    "        \n",
    "        # add current DOI to start_id \n",
    "        paper_cite_paper[\"start_id\"].extend([doi] * len(end_dois))\n",
    "        \n",
    "        # add randomized DOI to end_id\n",
    "        paper_cite_paper[\"end_id\"].extend(end_dois)\n",
    "    return(paper_cite_paper)\n",
    "\n",
    "# extract cite info\n",
    "paper_cite_paper = generate_paper_cite_paper(input_file_path)\n",
    "\n",
    "# write paper_cite_paper.CSV\n",
    "output_file_name = \"paper_cite_paper.csv\"\n",
    "output_file_path = os.path.join(file_path, output_file_name)\n",
    "export_to_csv(paper_cite_paper, output_file_path)\n",
    "\n",
    "print(\"paper_cite_paper.csv write to:\", output_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
